---
title: "Sandboxes: How AI Agents Safely Run Untrusted Code"
date: "2025-11-08"
excerpt: "AI agents write code on-the-fly—code you've never seen before. How do you run it safely? I discovered why sandboxes are the critical infrastructure enabling Anthropic's 98.7% efficiency breakthrough."
template: "article"
category: "AI Infrastructure"
---

## The Discovery

I was reading [Anthropic's recent article on code execution with MCP](https://www.anthropic.com/engineering/code-execution-with-mcp)—they achieved a **98.7% reduction in token usage**, which is massive. But throughout the article, one word kept appearing: **sandbox**.

"Code execution in secure sandboxes..."
"Agents write code that runs in a sandbox environment..."
"Sandbox infrastructure enables..."

![Screenshot from Anthropic's article highlighting sandboxing requirements](/images/anthropic-sandbox-mention.png)
*Anthropic's article mentions that "Running agent-generated code requires a secure execution environment with appropriate **sandboxing**, resource limits, and monitoring."*

The concept wasn't explained in detail. It was assumed knowledge. But clearly, it was *critical* to everything they were describing.

Then it hit me: **AI agents write code on-the-fly—code you've never reviewed. How do you run it safely?**

This is fundamentally different from traditional computing. When you deploy your application in a container, you wrote (or at least reviewed) every line of code. You trust it. But AI agents? They generate custom code for each task, seconds before execution. You cannot review it. You cannot trust it by default.

So I went deep. I wanted to understand: What exactly *is* a sandbox? Why does it solve the trust problem? And why does Anthropic—and increasingly, the entire industry—seem to believe this is foundational infrastructure?

Here's what I discovered. And why sandboxes are the critical infrastructure enabling safe AI agent execution.

---

## The Trust Spectrum: Understanding What Changed

To understand why sandboxes exist, you need to understand the question that changed everything: **Do you trust the code you're running?**

Traditional infrastructure assumes you control the code. You write it, test it, deploy it. Even with containers—you're deploying *your* applications. The code is trusted because you created it.

AI agents broke this assumption. They generate code in real-time that you've never seen before. This isn't a deployment problem. It's a **trust problem**.

### The Infrastructure That Already Existed

By the 2010s, we had **two parallel solutions** for different problems:

| **Containers (Docker, 2013)** | **Sandboxes (Bubblewrap, Chrome, 2010s)** |
|-------------------------------|-------------------------------------------|
| **Purpose:** Deploy YOUR apps | **Purpose:** Run UNTRUSTED code safely |
| You wrote the Dockerfile | Assume code is hostile |
| Long-running services | Ephemeral execution |
| **Examples:** Docker, Kubernetes | **Examples:** Bubblewrap, Firejail, browser sandboxes |

**These aren't sequential. They coexisted, solving different problems.**

### What Changed in 2020s: AI Agents

AI agents created a **NEW use case** for an OLD technology:

**The challenge:** AI agents generate custom code for each task. You've never reviewed it. You need to run it safely.

**The solution:** Sandboxes—technology that was ALREADY designed for untrusted code.

**Anthropic's breakthrough:** Using sandboxes for AI-generated code execution led to 98.7% token reduction.

**This isn't about new technology. It's about applying the RIGHT technology to a NEW problem.**

Both use similar Linux primitives (namespaces, cgroups), but solve fundamentally different problems:
- **Containers** = deployment infrastructure (ship YOUR apps)
- **Sandboxes** = execution infrastructure (run UNTRUSTED code)

AI agents don't need to *deploy* applications. They need to *execute* code they just wrote—safely.

---

## Why Sandboxes for AI Agents?

Here's the breakthrough: **AI agents need to write and execute code—code you cannot trust.**

Think about the workflow:
1. You ask an agent: "Analyze this customer data for trends"
2. The agent *writes Python code* to do it
3. The agent *runs that code* immediately
4. You get results

Here's the problem: **You never saw the code. You never reviewed it. How do you run it safely?**

This isn't a theoretical concern. AI-generated code could:
- Access files it shouldn't
- Make network calls you didn't authorize
- Crash and take your system with it
- Execute malicious operations (intentionally or by mistake)

### Why Sandboxes Specifically?

When AI writes code, you need to run it safely. What are your options?

**❌ Containers?**
- Assume you wrote the Dockerfile
- Not designed for hostile code
- Built for deployment, not ephemeral execution

**❌ VMs?**
- Too slow (seconds to start)
- AI needs millisecond-level responsiveness
- Overhead kills the workflow

**❌ Traditional serverless?**
- Same trust assumptions as containers
- Expects you to package the code
- Not built for zero-trust execution

**✅ Sandboxes?**
- Purpose-built for untrusted code (since 2010s)
- Millisecond startup (ephemeral by design)
- Zero-trust model (assume code is hostile)
- **AI agents just gave them a killer use case**

The technology existed. AI agents made it essential. But wait—aren't sandboxes just containers? Let's clear that up.

---

## What IS a Sandbox?

**A sandbox is a zero-trust execution environment.**

Think of it as a secure containment chamber for dangerous code:

- **Assumes hostility:** Every line of code is treated as potentially dangerous
- **Total isolation:** Can't access your files, network, or system
- **Ephemeral:** Exists only for the execution, then destroyed
- **Observable:** You get results (stdout, stderr, exit code), nothing more

**Real-world analogies:**

**Kids' sandbox:** They can build anything, make a mess, experiment. But the sand stays contained—it doesn't get all over the house. When they're done, you knock it down and start fresh.

**Bomb disposal chamber:** Put something dangerous inside, trigger it safely, see what happened, clean up. The key isn't just isolation—it's **zero-trust isolation for untrusted payloads**.

**Examples you already use:**
- **Chrome's sandbox:** Runs untrusted web code safely
- **Bubblewrap:** Sandboxes Linux applications
- **Firejail:** Isolates applications from your system

**For AI agents:** Cloudflare Workers, AWS Firecracker, and others adapted this proven technology for AI-generated code execution.

**NOT like containers:** Containers are deployment packaging for YOUR applications. Sandboxes are execution chambers for code you've never seen.

---

## But Aren't Sandboxes Just Containers?

**"Wait, can't I just use Docker containers for this?"**

You *could*, but here's the key difference:

**Containers** = deployment infrastructure
- You package YOUR application
- It runs for days/weeks
- You control the Dockerfile
- Think: Cargo ship delivering your product

**Sandboxes** = execution infrastructure
- Run UNTRUSTED code on-the-fly
- Ephemeral (milliseconds)
- Assume code is hostile
- Think: Bomb disposal chamber for dangerous payloads

**The analogy:** Using containers for AI-generated code is like using a cargo ship to deliver a single letter. Or using a restaurant kitchen to cook one experimental dish someone handed you on a napkin.

Both use similar tech (Linux namespaces, cgroups), but the architectural intent is completely different. **AI agents don't need to deploy applications—they need to execute code they just wrote, safely.**

---

## Ready to Build?

Now that you understand what sandboxes are and why they matter, it's time to experience them firsthand.

Want to run your own sandbox? The hands-on tutorial shows you how to:
- Set up a local sandbox in 2 minutes
- Execute AI-generated code safely
- Build interactive examples
- Deploy to production

**[→ Read the Tutorial: Building with Sandboxes](/articles/building-with-sandboxes-tutorial)**

Or explore with Cloudflare directly:
- **[Cloudflare Sandbox Documentation](https://developers.cloudflare.com/sandbox/)** - Official setup guide
- **[Get Started Guide](https://developers.cloudflare.com/sandbox/get-started/)** - Quick start in 5 minutes

---

## The AI Agent Connection (The "Aha!" Moment)

You just did what AI agents do. But here's the critical difference:

**You clicked "Run." AI agents *write* the code, then run it.**

Think about what you just experienced:
1. You ran Python code in isolation
2. Got back structured results
3. The sandbox kept everything safe
4. It happened instantly, globally

**Now imagine this:**
- An AI agent receives your request: "Analyze this customer data and find patterns"
- The agent *writes* a Python script to process the data
- Executes it in a sandbox (just like you did)
- Gets the results without ever exposing raw data to the model
- Returns insights to you

**This is the breakthrough Anthropic discovered.**

Instead of loading 150,000 tokens of tool definitions into context, AI agents:
- Write custom code for each task (2,000 tokens)
- Execute it in sandboxes
- Process data safely and efficiently
- **98.7% token reduction**

**The power multiplies:**
- Agents build libraries of reusable scripts ("skills")
- Each task generates optimized code
- Sensitive data stays in the sandbox
- Workflows become dynamic, not static
- Every problem gets a custom solution

You've now experienced the infrastructure behind AI's future. Sandboxes aren't just a tool—they're what makes truly capable AI agents possible.

---

## Why This Matters: Anthropic's World of Possibilities

Remember Anthropic's 98.7% token reduction? That was only possible because of sandboxes.

Here's why:

**Without sandboxes:** AI agents make direct tool calls. Every tool definition loads into context (150,000 tokens). Every intermediate result flows through the model (duplicate data, wasted tokens, high costs).

**With sandboxes:** Agents write code that runs in a sandbox. Load only the tools you need (2,000 tokens). Process data in the sandbox before returning results to the model. 98.7% reduction.

But the efficiency gains are just the beginning. Sandboxes unlock an entire world of possibilities:

### What Becomes Possible

**1. Safe AI Code Execution**
AI models can generate code (they're good at it). But you can't just execute that code in your production environment. Sandboxes give you a safe place to run AI-generated code at scale.

**2. Privacy-Preserving Workflows**
Sensitive data can flow through the sandbox without ever entering the model's context. Process customer data, run analytics, generate reports—all while keeping PII tokenized or isolated.

**3. Long-Running Processes**
Unlike typical serverless functions (30 seconds max), sandboxes can run for 45+ minutes. CI/CD pipelines, data processing, model training—all possible.

**4. Continuous Learning**
Agents can save their working code as reusable "skills." Over time, they build a library of capabilities. They get better without retraining the model.

**5. Dynamic Workflows**
This is the big one. Instead of hard-coded, static workflows, agents can create workflows on-demand. "Here's what I need to do. Let me write the code to do it. Done." Every workflow is unique. Every solution is tailored.

Anthropic didn't just discover a performance optimization. They discovered a new way of building with AI. And sandboxes are the infrastructure that makes it possible.

---

## The Seed is Planted

You now understand what sandboxes are. You've run one locally. You've seen how AI agents use them. And you understand why Anthropic's breakthrough was only possible because of this infrastructure.

*Sandboxes are to AI agents what containers were to cloud computing.*

They're not just a tool. They're foundational infrastructure.

But understanding what they are is just the beginning. In the next article, we'll explore how to actually build with them—the architecture, deployment, and real-world patterns that make AI agents truly capable.

For now, I want you to sit with this idea: **What becomes possible when AI agents can write and execute code safely at global scale?**

The future Anthropic described? It's being built on sandboxes.

---

## Resources

**Learn More:**
- [Anthropic's Code Execution with MCP](https://www.anthropic.com/engineering/code-execution-with-mcp) - The article that started this exploration
- [Cloudflare Sandbox Documentation](https://developers.cloudflare.com/sandbox/) - Official docs and guides
- [Model Context Protocol](https://modelcontextprotocol.io/) - The standard for AI-tool integration

**Experiment:**
- Get started: [Cloudflare Sandbox Get Started Guide](https://developers.cloudflare.com/sandbox/get-started/)
- Quick start: `npm create cloudflare@latest my-sandbox -- --template=cloudflare/sandbox-sdk/examples/minimal`
- Custom worker code shown in Step 2 above (includes blog integration endpoint)
- Explore the [Cloudflare Sandbox SDK](https://github.com/cloudflare/sandbox-sdk) on GitHub

---

*Coming next: "Sandbox Architecture Deep Dive: How to Build Production AI Agents"*
